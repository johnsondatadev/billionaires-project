---
title: "An Analysis of Billionaires of the World"
author:
  - name: "Akash Agrawal Bejarano, Ama K. Appau, Johnson Odejide, Josh Hall"
    email: {}, {}, bo5104a@american.edu, {}
    affiliation: 
      - name: American University
        city: Washington
        state: DC
        url: www.american.edu
copyright: 
  holder: Machine Teachers
  year: 2023
format: 
  pdf:
    toc: true
    toc-title: Table of Contents
    toc-location: left
    toc-depth: 2
    toc-expand: true
editor: visual
execute: 
  warning: false
  error: false
theme: 
  light: flatly
  dark: darkly
---

## 01. Problem Definition

Here, we define the goals, objectives, and success criteria for your machine learning project as well as determine what type of problem it is (classification, regression, clustering, etc.).

## 02. Data Collection

Data Source - <https://www.kaggle.com/datasets/nelgiriyewithana/billionaires-statistics-dataset?select=Billionaires+Statistics+Dataset.csv>

Data Description:

-   **rank**: The ranking of the billionaire in terms of wealth.

-   **finalWorth**: The final net worth of the billionaire in U.S. dollars.

-   **category**: The category or industry in which the billionaire's business operates.

-   **personName**: The full name of the billionaire.

-   **age**: The age of the billionaire.

-   **country**: The country in which the billionaire resides.

-   **city**: The city in which the billionaire resides.

-   **source**: The source of the billionaire's wealth.

-   **industries**: The industries associated with the billionaire's business interests.

-   **countryOfCitizenship**: The country of citizenship of the billionaire.

-   **organization**: The name of the organization or company associated with the billionaire.

-   **selfMade**: Indicates whether the billionaire is self-made (True/False).

-   **status**: "D" represents self-made billionaires (Founders/Entrepreneurs) and "U" indicates inherited or unearned wealth.

-   **gender**: The gender of the billionaire.

-   **birthDate**: The birthdate of the billionaire.

-   **lastName**: The last name of the billionaire.

-   **firstName**: The first name of the billionaire.

-   **title**: The title or honorific of the billionaire.

-   **date**: The date of data collection.

-   **state**: The state in which the billionaire resides.

-   **residenceStateRegion**: The region or state of residence of the billionaire.

-   **birthYear**: The birth year of the billionaire.

-   **birthMonth**: The birth month of the billionaire.

-   **birthDay**: The birth day of the billionaire.

-   **cpi_country**: Consumer Price Index (CPI) for the billionaire's country.

-   **cpi_change_country**: CPI change for the billionaire's country.

-   **gdp_country**: Gross Domestic Product (GDP) for the billionaire's country.

-   **gross_tertiary_education_enrollment**: Enrollment in tertiary education in the billionaire's country.

-   **gross_primary_education_enrollment_country**: Enrollment in primary education in the billionaire's country.

-   **life_expectancy_country**: Life expectancy in the billionaire's country.

-   **tax_revenue_country_country**: Tax revenue in the billionaire's country.

-   **total_tax_rate_country**: Total tax rate in the billionaire's country.

-   **population_country**: Population of the billionaire's country.

-   **latitude_country**: Latitude coordinate of the billionaire's country.

-   **longitude_country**: Longitude coordinate of the billionaire's country.

## 03. EDA

Here, we explore and visualize the data to gain insights, identifying patterns, trends, and potential outliers. We assess the distribution of variables, consider the relationships between variables.

```{r, message=FALSE}
library(tidyverse)
library(tidymodels)
# library(recipeselectors)
library(dplyr)
library(ggplot2)
library(leaps)
library(glmnet)
library(corrplot)
library(pls)
```

```{r, message=FALSE}
data <- read_csv("data/Billionaires.csv")
# head(data)
# dim(data)
glimpse(data)
# colSums(is.na(data))
```

The data contains 2640 observations of 35 features

```{r}
#I removed the columns with a lot of NAs and the ones which we wont use like latitude and longitude
dim(data)
data <- mutate(data, age = na_if(age, -1))
data <- data[-c(4,6:11,13,15:24,26,28,29,31,34,35)]
```

```{r}

View(data)

# corrplot(cor(data, use = "pairwise.complete.obs"))

numeric_data <- select_if(data, is.numeric) 

View(numeric_data)
# cor_bill <- cor(numeric_data)
# corrplot(cor_bill)
```

```{r EDA}

```

## 04. Data Preprocessing

Here, we handle missing data and outliers, normalize or standardize data if necessary. We encode categorical variables and split the data into training, validation, and test sets.

```{r DataProcessing}
#omitted all nas and then parsed the gdp column to make it numeric
colSums(is.na(data))
cleaned_data <- na.omit(data)
dim(cleaned_data)
colSums(is.na(cleaned_data))

Classbill <-
  cleaned_data |>
  relocate(selfMade,.before = rank)

Classbill$gdp_country = as.numeric(gsub("[\\$,]", "", Classbill$gdp_country))
```

```{r}
numeric_data <- select_if(Classbill, is.numeric) 
cor_bill <- cor(numeric_data)
# corrplot(cor_bill, method = 'number')
corrplot(cor_bill, method = 'shade', order = 'AOE', diag = F)
# corrplot(cor_bill, method = 'shade', order = 'AOE', addCoef.col = 'black', tl.pos = 'd',cl.pos = 'n', col = COL2('BrBG'), diag = FALSE)
# corrplot(cor_bill, type = "upper", order = 'hclust', addCoef.col = 'black', tl.pos = 'd',
#          cl.pos = 'n', col = COL2('PiYG'))
# test_cor = cor.mtest(numeric_data, conf.level = 0.95)
# corrplot(cor_bill, p.mat = test_cor$p, insig = 'p-value')
# corrplot.mixed(cor_bill, order = "AOE")
```

While it logically appears as though rank should be highly correlated with `finalWorth`, the plot indicates that it has a weak negative correlation with it. However, there is a high negative correlation between `life_expectancy_country` and `cpi_country`. Similarly, there is a fair positive correlation between `population_country` and `total_tax_rate_country`.

## 05. Feature Engineering

Here, we create relevant features from the raw data. We perform feature selection to identify the most important features, applying domain knowledge to transform data effectively.

```{r FeatureEngineering}
# Correlation Analysis
missing_values <- colSums(is.na(data))

print(missing_values)

complete_data <- Classbill[complete.cases(Classbill), ]

numeric_data <- complete_data[sapply(complete_data, is.numeric)]

correlation_results <- cor(numeric_data[, -which(names(numeric_data) == "finalWorth")], numeric_data$finalWorth)

# Print the correlation results
print(correlation_results)
```

Rank is correlated with finalWorth. We remove that and plot the correlation to inspect for multicollinearity.

```{r}
clean_numeric_data <- numeric_data[, -1]
correlation_matrix <- cor(numeric_data[, -which(names(numeric_data) == "finalWorth")])
print(correlation_matrix)
```

```{r VIF-Multicollinearity}
# install.packages("car")
library(car)

vif_values <- vif(lm(finalWorth ~ ., data = numeric_data))
print(vif_values)
```

```{r Correlation-Heatmap}
# install.packages("heatmaply")
library(heatmaply)

# Compute correlation matrix
correlation_matrix <- cor(clean_numeric_data[, -which(names(clean_numeric_data) == "finalWorth")])

# Create interactive heatmap
heatmaply(correlation_matrix, symmetric = TRUE)

```

`cpi_country` and `life_expectancy_country` are highly correlated.

### Random Forest Feature Selection

```{r FeatureSelection-RandomForest}
# install.packages("randomForest")
library(randomForest)

set.seed(123) 

rf_model <- randomForest(finalWorth ~ ., data = complete_data)

# Get feature importance
importance <- importance(rf_model)

# Sort features by importance
sorted_importance <- importance[order(importance, decreasing = TRUE), ]

# Print or inspect the sorted feature importance
print(sorted_importance)
```

Important features based on random forest selection are `rank, age, category, total_tax_rate_country, cpi_country, gdp_country, life_expectancy_country, selfMade, population_country, gender`

```{r FeatureSelection-LASSO}
library(glmnet)

# non_numeric_cols <- sapply(Classbill, is.character)
# 
# # If non-numeric columns are present, encode them (example using dummy encoding)
# if (sum(non_numeric_cols) > 0) {
#   new_data <- model.matrix(~ . - 1, data = Classbill)  # Remove intercept
# }
# 
# # Remove missing values if any
# new_data <- na.omit(new_data)
# 
# clean_complete_data <- cleaned_data[complete.cases(new_data), ]
# Extract predictors and target variable
X <- as.matrix(clean_numeric_data[, -which(names(clean_numeric_data) == "finalWorth")])
y <- clean_numeric_data$finalWorth

# Fit Lasso regression model using glmnet
lasso_model <- cv.glmnet(X, y, alpha = 1)  # alpha = 1 for Lasso

# Plot the cross-validated mean squared error vs. lambda
plot(lasso_model)

# Select the best lambda value
best_lambda <- lasso_model$lambda.min
cat("Best lambda value:", best_lambda, "\n")

# Get coefficients for the selected lambda
lasso_coef <- coef(lasso_model, s = best_lambda)
print(lasso_coef)
```

Based on LASSO, `age, cpi_country, life_expectancy_country, total_tax_rate_country, and population_country` are important predictors.

```{r FeatureSelection-Linear-R2CPBIC, warning=FALSE}
set.seed(123)
training <- .70

z <- sample(nrow(complete_data), floor(training*nrow(complete_data)))
lm_train <- complete_data[z,] 
lm_test <- complete_data[-z,] 

full_base_model <- lm(finalWorth ~ ., data = lm_train)
summary(full_base_model)

# Set up for obtaining results
reg.fit <- regsubsets(finalWorth ~ ., data = lm_train, nvmax = 10)
sum_reg <- summary(reg.fit)

# R2
paste("The R2 values are:")
sum_reg$adjr2
paste(" The best R2 value belongs to a model using ", which.max(sum_reg$adjr2), "variables.")

#BIC
paste("The minimum BIC belongs to a model with", which.min(sum_reg$bic), "variables.")
paste("BIC variable breakdown:")
sum_reg$which[which.min(sum_reg$bic),]

# CP
paste("The minimum BIC belongs to a model with", which.min(abs(sum_reg$cp - 0:10)), "variables.")
paste("CP variable breakdown:")
sum_reg$which[which.min(abs(sum_reg$cp - 0:10)),]
```

## 06. Model Selection

In this section, we choose the appropriate machine learning algorithms for our problem, experiment with different models and techniques to find the best one. We tune hyperparameters for optimal performance.

```{r ModelSelection_LogisticClassification}
#Classification LOGISTIC to predict whether the billonaire is self made or not
set.seed(123)
training <- .70
s <- sample(nrow(Classbill), floor(training*nrow(Classbill)))
Ttrain<-Classbill[s,] 
Ttest<-Classbill[-s,] 

a <-  glm(as.factor(selfMade) ~ ., family = "binomial", data = Ttrain)

Testp<- predict(a, type = "response",  newdata = Ttest)

threshold <- seq(0, 1, .01)
TPR <-  FPR <- err.rate <- rep(0, length(threshold))


for (i in seq_along(threshold)) {
Yhat <- rep(NA_character_, nrow(Ttest)) 
Yhat <-  ifelse(Testp >= threshold[[i]], "TRUE", "FALSE")

err.rate[i] <- mean(Yhat != Ttest$selfMade)
TPR[[i]] <- sum(Yhat == "TRUE" & Ttest$selfMade == "FALSE")/
  sum(Ttest$selfMade == "TRUE")
FPR[[i]] <- sum(Yhat == "TRUE" & Ttest$selfMade == "FALSE")/
  sum(Ttest$selfMade == "FALSE")
}

table(Ttest$selfMade)
min(err.rate)
threshold[which.min(err.rate)]
```

```{r ModelSelection_KNNClassification}
#removing the categorical predictors category and gender
Classbill1 =Classbill[-c(4,6)]
library(class)
set.seed(123)
training <- .70
s<- sample(nrow(Classbill1), floor(training*nrow(Classbill1)))

Xtraining<-Classbill1[s,2:9] 
Ytraining<- Classbill1$selfMade[s]  
Xtesting <- Classbill1[-s,2:9]
Ytesting <- Classbill1$selfMade[-s]

z <- rep(1:50)
x <- rep(1:50)
c <- rep(1:50)

for (k in 1:50){
  D <- knn(Xtraining, Xtesting, Ytraining, k = k) 
  z[k] <- mean(D != Ytesting) 
  x[k] <- sum(D == 1 & Ytesting == 1) / sum(Ytesting == 1) 
  c[k] <- sum(D == 1 & Ytesting == 0) / sum(Ytesting == 0)  
}

paste("The k which minimizes the prediction error rate is",which.min(z))
paste("The associated error rate is", z[which.min(z)])
```

```{r}
set.seed(123)
training <- .70
D <- knn(Xtraining, Xtesting, Ytraining, k = 14) 
table(Ytesting,D)
```

```{r}
cr = (table(Ytesting, D)[1, 1] + table(Ytesting, D)[2, 2])/(0.3*nrow(Classbill1))
paste("The classification rate is", cr)
```

```{r ModelSelection_Stepwise}
null_model <- lm(finalWorth ~ 1, data = lm_train)
reg_step <- step(full_base_model, scope = list(lower = null_model, upper = full_base_model), method = "backward") # For some reason not running? 
```

```{r Lasso_Ridge_Setup}
# Further setting up training and testing data
set.seed(123)

x_train <- model.matrix(full_base_model)[,-1]
y_train <- lm_train$finalWorth

reg_test <- lm(finalWorth ~ ., data = lm_test) 
x_test <- model.matrix(reg_test)[,-1]
y_test <- lm_test$finalWorth
```

```{r Lasso Training-1se}
# Fit Lasso regression model using glmnet
trained_lasso_model <- cv.glmnet(x_train, y_train, alpha = 1)  # alpha = 1 for Lasso

# Plot the cross-validated mean squared error vs. lambda.min
plot(trained_lasso_model)

# Lasso 1se
trained_lasso_1se <- glmnet(x_train, y_train, lambda = trained_lasso_model$lambda.1se)
coef(trained_lasso_1se)

# Plot the cross-validated mean squared error vs. lambda 1se
plot(trained_lasso_1se)
```

```{r LassoTraining-LambdaMin}
#Lasso Min
trained_lasso_min <- glmnet(x_train, y_train, lambda = trained_lasso_model$lambda.min)
coef(trained_lasso_min)
```

Lambda 1se eliminates all variables, therefore best to use the lambda min.

```{r RidgeTraining}
# Using cross validation results to select lambda
set.seed(123)
trained_ridge <- cv.glmnet(x_train, y_train, alpha = 0 )
trained_ridge
# Ridge plot
plot(trained_ridge)

# Lambda Min Ridge
trained_ridge_min <- glmnet(x_train, y_train, alpha = 0, lambda = trained_ridge$lambda.min)
coef(trained_ridge_min)

# Lambda Min Ridge
trained_ridge_1se <- glmnet(x_train, y_train, alpha = 0, lambda = trained_ridge$lambda.1se)
coef(trained_ridge_1se)
```

## 07. Model Training

Here, we train the selected model on the training data monitor the model performance on the validation set.

```{r ModelTraining-StratifiedSampling}

library(tidymodels)

cleaned_df <- 
  Classbill |> 
  mutate(selfMade = ifelse(selfMade, 'yes', 'no')) |> 
  mutate(selfMade = as.factor(selfMade))

# The class is imbalanced, hence, the need to do a stratified sampling on the training and test sets.
cleaned_df |> 
  count(selfMade) |> 
  mutate(percent = n / sum(n))

set.seed(1234)

df_split <- initial_split(cleaned_df, strata = selfMade)
df_train <- training(df_split)
df_test <- testing(df_split)
dim(df_train)
dim(df_test)
```

```{r ModelTraining-LR-tidymodel}
rf_df <- 
  cleaned_df |> 
  select(-category)

non_numeric_cols <- sapply(rf_df, function(x) !is.numeric(x))

# Convert non-numeric columns to factors (example)
rf_df[, non_numeric_cols] <- lapply(rf_df[, non_numeric_cols], as.factor)

# Create a recipe for pre-processing
data_recipe <- recipe(finalWorth ~ ., data = rf_df) %>%
  step_integer(all_nominal(), -all_outcomes()) %>%  # Convert nominal variables to integers
  step_dummy(all_nominal(), -all_outcomes()) %>%   # Dummy encode nominal variables
  step_normalize(all_predictors())

# data_recipe <- recipe(finalWorth ~ ., data = rf_df) |> 
#   step_normalize(all_predictors())

df_split <- initial_split(rf_df, prop = 0.8, strata = selfMade)
data_train <- training(df_split)
data_test <- testing(df_split)

# lm_fit <- lm(finalWorth ~ ., data = data_train)

# summary(lm_fit)
lm_spec <- linear_reg() |>
  set_engine("lm")

# Create a workflow
lm_workflow <- workflow() |>
  add_recipe(data_recipe) |>
  add_model(lm_spec)

# Train the model using stratified sampling
lm_fit <- fit(lm_workflow, data = data_train)

# Make predictions on the test set
predictions <- predict(lm_fit, data_test)

# Evaluate the model
evaluation_metrics <- metrics(data = predictions, truth = data_test$finalWorth, estimate = .pred)
print(evaluation_metrics)
```

```{r PCRTraining-Setup}
set.seed(123)

train_pcr_fit <- pcr(finalWorth ~ ., data = lm_train, scale = TRUE, validation = "CV")
summary(train_pcr_fit)
```

Lowest adjusted CV at 21 components for 9905 MSREP.

```{r PCRTraining}
set.seed(123)

pcr_fitM <- pcr(finalWorth ~ ., data = lm_train, scale = TRUE, ncomp = 21)
```

```{r PLSTraining-Setup}
set.seed(123)

pls_fit <- plsr(finalWorth ~ ., data = lm_train, scale = TRUE, validation = "CV")
summary(pls_fit)
```

Lowest adjusted CV at 3 components for 9916.

```{r PLSTraining}
set.seed(123)

pls_fitM <- plsr(finalWorth ~ ., data = lm_train, scale = TRUE, ncomp = 3)
```

## 08. Model Evaluation

Here, we evaluate the model's performance using appropriate metrics (e.g., accuracy, RMSE). Compare the model's performance to baselines and expectations.

```{r ModelEvaluation_LogisticClassification}

```

```{r ModelEvaluation_KNNClassification}

```

```{r LassoEvaluation}
yHat <- predict(trained_lasso_1se, newx = x_test, s = "lambda.1se")
pmse_l1se <- mean((yHat - y_test)^2)
pmse_l1se

trained_lasso_1se$df

yHat <- predict(trained_lasso_min, newx = x_test, s = "lambda.min")
pmse_lmin <- mean((yHat - y_test)^2)
pmse_lmin

trained_lasso_min$df
```

```{r RidgeEvaluation}
yHat <- predict(trained_ridge_min, newx = x_test, s = "lambda.min")
pmse_r <-  mean((yHat - y_test)^2)
pmse_r
trained_ridge_min$df

yHat <- predict(trained_ridge_1se, newx = x_test, s = "lambda.1se")
pmse_r <-  mean((yHat - y_test)^2)
pmse_r
trained_ridge_1se$df
```

```{r PCREvaluation}
yHat_pcr <- predict(pcr_fitM, newdata = lm_test, ncomp = 21)

mean((yHat_pcr - lm_test$finalWorth)^2)

validationplot(train_pcr_fit)
```

```{r PLSEvaluation}
yHat_pls <- predict(pls_fitM, newdata = lm_test, ncomp = 3)
mean((yHat_pls - lm_test$finalWorth)^2)

validationplot(pls_fit)
```

## 09. Model Validation

Here, we use the test data to assess the model's generalization performance to ensure that the model performs well on unseen data.

```{r ModelValidation}

```

## 10. Ethical Considerations

This is not a section perse, it's just for us to ensure that the model and data collection processes adhere to ethical guidelines and do not perpetuate biases or harm.
