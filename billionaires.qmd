---
title: "An Analysis of Billionaires of the World"
author:
  - name: "Akash Agrawal Bejarano, Ama K. Appau, Johnson Odejide, Josh Hall"
    email: {}, {}, bo5104a@american.edu, {}
    affiliation: 
      - name: American University
        city: Washington
        state: DC
        url: www.american.edu
copyright: 
  holder: Machine Teachers
  year: 2023
format: 
  pdf:
    toc: true
    toc-title: Table of Contents
    toc-location: left
    toc-depth: 2
    toc-expand: true
editor: visual
execute: 
  warning: false
  error: false
theme: 
  light: flatly
  dark: darkly
---

## 01. Problem Definition

Here, we define the goals, objectives, and success criteria for your machine learning project as well as determine what type of problem it is (classification, regression, clustering, etc.).

## 02. Data Collection

Data Source - <https://www.kaggle.com/datasets/nelgiriyewithana/billionaires-statistics-dataset?select=Billionaires+Statistics+Dataset.csv>

Data Description:

-   **rank**: The ranking of the billionaire in terms of wealth.

-   **finalWorth**: The final net worth of the billionaire in U.S. dollars.

-   **category**: The category or industry in which the billionaire's business operates.

-   **personName**: The full name of the billionaire.

-   **age**: The age of the billionaire.

-   **country**: The country in which the billionaire resides.

-   **city**: The city in which the billionaire resides.

-   **source**: The source of the billionaire's wealth.

-   **industries**: The industries associated with the billionaire's business interests.

-   **countryOfCitizenship**: The country of citizenship of the billionaire.

-   **organization**: The name of the organization or company associated with the billionaire.

-   **selfMade**: Indicates whether the billionaire is self-made (True/False).

-   **status**: "D" represents self-made billionaires (Founders/Entrepreneurs) and "U" indicates inherited or unearned wealth.

-   **gender**: The gender of the billionaire.

-   **birthDate**: The birthdate of the billionaire.

-   **lastName**: The last name of the billionaire.

-   **firstName**: The first name of the billionaire.

-   **title**: The title or honorific of the billionaire.

-   **date**: The date of data collection.

-   **state**: The state in which the billionaire resides.

-   **residenceStateRegion**: The region or state of residence of the billionaire.

-   **birthYear**: The birth year of the billionaire.

-   **birthMonth**: The birth month of the billionaire.

-   **birthDay**: The birth day of the billionaire.

-   **cpi_country**: Consumer Price Index (CPI) for the billionaire's country.

-   **cpi_change_country**: CPI change for the billionaire's country.

-   **gdp_country**: Gross Domestic Product (GDP) for the billionaire's country.

-   **gross_tertiary_education_enrollment**: Enrollment in tertiary education in the billionaire's country.

-   **gross_primary_education_enrollment_country**: Enrollment in primary education in the billionaire's country.

-   **life_expectancy_country**: Life expectancy in the billionaire's country.

-   **tax_revenue_country_country**: Tax revenue in the billionaire's country.

-   **total_tax_rate_country**: Total tax rate in the billionaire's country.

-   **population_country**: Population of the billionaire's country.

-   **latitude_country**: Latitude coordinate of the billionaire's country.

-   **longitude_country**: Longitude coordinate of the billionaire's country.

## 03. EDA

Here, we explore and visualize the data to gain insights, identifying patterns, trends, and potential outliers. We assess the distribution of variables, consider the relationships between variables.

```{r}
```

```{r}
library(tidyverse)
library(tidymodels)
library(recipeselectors)
library(dplyr)
library(ggplot2)
library(skimr)
```

```{r}
data <- read_csv("data/Billionaires.csv", show_col_types = F)
# head(data)
# dim(data)
glimpse(data)
# colSums(is.na(data))
```

The data contains 2640 observations of 35 features

```{r}
skimr::skim(data)
```

```{r}
#I removed the columns with a lot of NAs and the ones which we wont use like latitude and longitude
dim(data)
data <- mutate(data, age = na_if(age, -1))
data <- data[-c(4,6:11,13,15:24,26,28,29,31,34,35)]
```

```{r}
tibble_df_cleaned <- 
  tibble_df |> 
  mutate(gdp_country = gsub("[$ ,]", "", gdp_country)) |> 
  mutate(gdp_country = as.numeric(gdp_country))

head(tibble_df_cleaned)
# |> 
#   head()
#   mutate(gdp_country = )
```

```{r EDA}
# Comparing male and female final worth
data |> 
  ggplot(aes(finalWorth, fill = gender)) + 
  geom_density(alpha = 0.8) +
  scale_x_log10()

# Comparing selfmade billionaires
data |> 
  ggplot(aes(finalWorth, fill = selfMade)) + 
  geom_density(alpha = 0.8) +
  scale_x_log10()

data |> 
  ggplot(aes(x = industries, finalWorth)) +
  geom_histogram(aes(fill = selfMade), stat = "identity") +
  coord_flip() +
  facet_wrap(~ gender)
```

## 04. Data Preprocessing

Here, we handle missing data and outliers, normalize or standardize data if necessary. We encode categorical variables and split the data into training, validation, and test sets.

Some Data Cleaning

`gpd_country`, for example, was formatted as 2,000,000. It was cleaned to remove the \\\$ and the commas.

`SelfMade` was transformed from **TRUE/FALSE** to `yes/no`

`category`, `industries`, `gender`, status were cast to factor type.

The resultant cleaned data is stored in a variable called **`cleaned_df`**

```{r DataProcessing}
#omitted all nas and then parsed the gdp column to make it numeric
colSums(is.na(data))
cleaned_data <- na.omit(data)
dim(cleaned_data)
colSums(is.na(cleaned_data))

Classbill <-
  cleaned_data |>
  relocate(selfMade,.before = rank)

Classbill$gdp_country = as.numeric(gsub("[\\$,]", "", Classbill$gdp_country))

# (Classbill$category) 
# (Classbill$industries)
# levels(as.factor(Classbill$title))
# head(Classbill)
```

```{r}
cleaned_df <- 
  Classbill |> 
  mutate(selfMade = ifelse(selfMade, 'yes', 'no')) |> 
  mutate(selfMade = as.factor(selfMade),
         category = as.factor(category),
         industries = as.factor(industries),
         gender = as.factor(gender),
         status = as.factor(status),
         country = as.factor(country)) |> 
  select(-country, -personName, -birthMonth, -birthDay, -c(cpi_country : longitude_country)) 

cleaned_df <- na.omit(cleaned_df)
summary(cleaned_df)

# tail(cleaned_df)
sapply(lapply(cleaned_df, unique), length)
```

## 05. Feature Engineering

Here, we create relevant features from the raw data. We perform feature selection to identify the most important features, applying domain knowledge to transform data effectively.

```{r FeatureEngineering}
cleaned_df_lr <- 
  cleaned_df |> 
  select(-city)

head(cleaned_df)
# 
# c("country", ["cpi_country" : "longitude_country"])
# 
summary(lm(finalWorth ~ ., cleaned_df_lr))
```

## 06. Model Selection

In this section, we choose the appropriate machine learning algorithms for our problem, experiment with different models and techniques to find the best one. We tune hyperparameters for optimal performance.

**Linear Regression**

```{r}
sapply(lapply(cleaned_df, unique), length)
```

```{r}
summary(lm(finalWorth ~ ., data = cleaned_df))
```

```{r}
summary(lm(finalWorth ~ gdp_country , data = tibble_df)) 
```

```{r}

tibble_df <- 
  tibble_df |> 
  mutate(selfMade = ifelse(selfMade, 'yes', 'no')) |> 
  mutate(selfMade = as_factor(selfMade)) 
  
# summary(lm(finalWorth ~ gdpCountry , data = tibble_df)) 


# glimpse(tibble_df)
# summary(lm(selfMade ~ ., data = tibble_df))
```

```{r LR_FullModel}

lr_data <- 
  tibble_df |> 
  mutate(selfMade = as.factor(selfMade)) |> 
  lm(finalWorth ~ .) 
# lr_fullmodel <- lm(finalWorth ~ ., data = data)
# summary(lr_fullmodel)
```

**Logistic Regression**

```{r ModelSelection_LogisticClassification}
#Classification LOGISTIC to predict whether the billonaire is self made or not
set.seed(123)
training <- .70
s <- sample(nrow(Classbill), floor(training*nrow(Classbill)))
Ttrain<-Classbill[s,] 
Ttest<-Classbill[-s,] 

a <-  glm(as.factor(selfMade) ~ ., family = "binomial", data = Ttrain)

Testp<- predict(a, type = "response",  newdata = Ttest)

threshold <- seq(0, 1, .01)
TPR <-  FPR <- err.rate <- rep(0, length(threshold))


for (i in seq_along(threshold)) {
Yhat <- rep(NA_character_, nrow(Ttest)) 
Yhat <-  ifelse(Testp >= threshold[[i]], "TRUE", "FALSE")

err.rate[i] <- mean(Yhat != Ttest$selfMade)
TPR[[i]] <- sum(Yhat == "TRUE" & Ttest$selfMade == "FALSE")/
  sum(Ttest$selfMade == "TRUE")
FPR[[i]] <- sum(Yhat == "TRUE" & Ttest$selfMade == "FALSE")/
  sum(Ttest$selfMade == "FALSE")
}

table(Ttest$selfMade)
min(err.rate)
threshold[which.min(err.rate)]
```

**KNN Classification**

```{r ModelSelection_KNNClassification}
#removing the categorical predictors category and gender
Classbill1 = Classbill[-c(4,6)]
library(class)
set.seed(123)
training <- .70
s<- sample(nrow(Classbill1), floor(training*nrow(Classbill1)))

Xtraining<-Classbill1[s,2:9] 
Ytraining<- Classbill1$selfMade[s]  
Xtesting <- Classbill1[-s,2:9]
Ytesting <- Classbill1$selfMade[-s]

z <- rep(1:50)
x <- rep(1:50)
c <- rep(1:50)

for (k in 1:50){
  D <- knn(Xtraining, Xtesting, Ytraining, k = k) 
  z[k] <- mean(D != Ytesting) 
  x[k] <- sum(D == 1 & Ytesting == 1) / sum(Ytesting == 1) 
  c[k] <- sum(D == 1 & Ytesting == 0) / sum(Ytesting == 0)  
}

paste("The k which minimizes the prediction error rate is",which.min(z))
paste("The associated error rate is", z[which.min(z)])
```

```{r}
set.seed(123)
training <- .70
D <- knn(Xtraining, Xtesting, Ytraining, k = 14) 
table(Ytesting,D)
```

```{r}
cr = (table(Ytesting, D)[1, 1] + table(Ytesting, D)[2, 2])/(0.3*nrow(Classbill1))
paste("The classification rate is", cr)
```

## 07. Model Training

Here, we train the selected model on the training data monitor the model performance on the validation set.

```{r ModelTraining}

library(tidymodels)

set.seed(123)
df_split <- initial_split()
```

## 08. Model Evaluation

Here, we evaluate the model's performance using appropriate metrics (e.g., accuracy, RMSE). Compare the model's performance to baselines and expectations.

```{r ModelEvaluation_LogisticClassification}

```

```{r ModelEvaluation_KNNClassification}

```

## 09. Model Validation

Here, we use the test data to assess the model's generalization performance to ensure that the model performs well on unseen data.

```{r ModelValidation}

```

## 10. Ethical Considerations

This is not a section perse, it's just for us to ensure that the model and data collection processes adhere to ethical guidelines and do not perpetuate biases or harm.
